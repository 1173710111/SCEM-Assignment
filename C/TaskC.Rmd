---
title: "TaskC Reporter"
author: "zerofrom"
date: "`r Sys.Date()`"
output:
  html_document:
     mathjax: default
  latex_engine: xelatex
  pdf_document: null
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## &#x20;**1. Description of Kruskal-Wallis test**

#### **Introduction**

The **Kruskal-Wallis test** is a hypothesis test used to determine whether there is a difference between several independent sample groups. Since it is the **non-parametric** counterpart of the single factor analysis of variance, the data used is not required to follow a normal distribution but at least ordinal or continuous(e.g., sales, fractions).&#x20;

The Kruskal-Wallis test is often considered as an extension of the **Mann-Whitney U test** because it allows for comparisons of more than 2 data groups. It also serves as a nonparametric alternative to **ANOVA test** for data that do not satisfy the normal distribution.

#### **The underlying assumptions**

Although the Kruskal-Wallis test is a non-parametric test and requires less data distribution, it still has some underlying assumptions. These assumptions need to be met to ensure the validity and correctness of the test results.

**1) Independent Groups:** The samples are independent of each other, meaning that the observations in each group are not related

**2) Ordinal or Continuous Data:** It can be used with ordinal data or continuous data that has been converted to ranks.

#### **Research questions and hypothesis**

The Kruskal-Wallis test is commonly used to compare differences among multiple independent sample data sets. For example, the question could be: Do the data come from the same general distribution? This research question leads to the null hypothesis and alternative hypothesis.&#x20;

**Null hypothesis:** Assumes that all groups have the same distributional trend and are not significantly different.&#x20;

**Alternative hypothesis:** Assumes that at least one of the sample groups has a different distributional trend.

#### **The test statistic**

While the test is often used as an indicator of differences in medians, strictly speaking, it does not directly test the medians. The Kruskal-Wallis test checks whether the rank sums of all the data groups are the same across groups, which is a bit different from saying that the medians are equal.&#x20;

The test statistic 𝐻 of the Kruskal-Wallis test is calculated as follows:

1\) Clarify the number of groups (or samples) involved in the study *m*;

2\) Calculate the sample size for each sample group as \(n_1, n_2, \dots, n_m \);

3\) Combine the data, keeping track of the samples from which group;

4\) Rank the data;

5\) Sum up the ranks of the data from each group separately as \(T_1, T_2, \dots, T_m \);

6\) Calculate the Kruskal-Wallis H statistic, which is distributed as chisquare, by:

\begin{equation}

H = \frac{12}{n(n+1)}\left(\frac{T_1^2}{n_1} + \frac{T_2^2}{n_2} + \dots + \frac{T_k^2}{n_k}\right) - 3(n+1)

\end{equation}

In conclusion, statistics for the Kruskal-Wallis test H is calculated using the formula as follows:

\begin{equation}

H = \frac{12}{n(n+1)} \sum\_{i=1}^k \frac{T_i^2}{n_i} - 3(n+1)

\end{equation}

#### **Calculation of p-values**

Under the condition that the original hypothesis(Null hypothesis) holds, the Kruskal-Wallis test statistic H approximately obeys a chi-square distribution with k-1 degrees of freedom. The parameter k represents the number of independent sample groups.

Based on the calculated H-value and degrees of freedom k-1 , check the table from the chi-square distribution or use the calculation tool to get the corresponding p-value.

If \(p\text{-value} \leq \alpha\), reject the null hypothesis (\(H\_0\)), which means that there is a significant difference among sample groups.

If \(p\text{-value} > \alpha\), do not reject the null hypothesis (\(H\_0\)), and there is no difference among the sample groups.

#### **Explanation of the hypothesis by the test statistic**

If the distributions of the groups are identical (the null hypothesis holds), the rank sum T is mainly affected by random fluctuations. Therefore there will be small differences between groups, resulting in a lower H-value.

On the contrary, if the distributions of the groups are significantly different (the alternative hypothesis holds), the rank sum T of some of the groups will significantly deviate from the other groups, resulting in a higher H-value.

Therefore, the size of the H-value can be used to measure the significance of the difference between the sample groups and thus distinguish between the null and alternative hypothesis.

## **2. Simulation studies**
#### **STUDY DESCRIPTION**
A Kruskal-Wallies test is performed using randomly generated data, in order to calculate the probability of a Type I error occurring under the null hypothesis. Then further compare the relationship between different significance levels and the probability of Type I error.

#### **Design of experiments**

**1) Setting of parameters**    
**random number seeding:** Ensure that the analysis is reproducible.    
**group_size:** The sample size of each group is set to 100.    
**alpha_levels:** \alpha = 0.05 is the most commonly used criterion in statistical studies, and this experiment allows for a full analysis of the performance of the test by extending it to smaller (0.005) and larger (0.1) ranges. Multiple significance levels are chosen to enhance the hierarchical and broad nature of the experiment.    
**num_trials:** A total of 5000 simulation trials are conducted. Increasing the number of simulations reduces the effect of random fluctuations.
***Code Segment***
```{r}
# Set parameters
set.seed(2024)
group_size <- 100
num_groups <- length(group_size)
alpha_levels <- c(0.005, 0.01,0.025, 0.05, 0.1)
num_levels <-length(alpha_levels)
num_trials <- 5000
```

**2) Function Design**  
**simulate_kruskal:** A function to take several sets of sample data and return the Kruskal-Wallis test for the p-value. This function integrates the sample data into a single data frame and calculates the test result.  
***Code Segment***  
```{r}
# Simulation function, input each group of sample data, return p_value
simulate_kruskal <- function(...){
  groups <- list(...)
  if (length(groups)<2){
    stop("There should be at least two groups of data.")
  }
  # Create data frame that integrate group data and group labels
  combined_data <- data.frame(
    value = unlist(groups),
    group = factor(rep(seq_along(groups), sapply(groups, length)))
  )
  # Kruskal-Wallis test
  kruskal_result <- kruskal.test(value~group, data=combined_data)
  return(kruskal_result$p.value)
}
```

**3) Simulation Procedure**  
**Step 1:** Randomly generate 4 sets of data that meet the null hypothesis (same distribution). In order to comply with the applicability  of the Kruskal-Wallis test, a non-normal distribution is chosen here for random sample generation (exponential distribution with \lamda=1), and generate 4 sample groups(>=2).  
**Step 2:** Call the function **simulate_Kruskal** to compute p-value of the Kruskal-Wallis test for each trial.  
**Step 3:** Compare the p-value with each significant level, and record the times of type I error.  
***Code Segment***  
```{r}
# Initialize the frame to store the results
simulation_data <- data.frame(
  alpha_levels = alpha_levels,
  type_I_error = numeric(num_levels),
  error_probability = numeric(num_levels)
)

# Start Simulation
for (i in 1:num_trials){
  # H0: There is no difference among sample groups.
  # Simulated data from the same distribution
  group1 <- rexp(group_size, rate = 1 )
  group2 <- rexp(group_size, rate = 1 )
  group3 <- rexp(group_size, rate = 1 )
  group4 <- rexp(group_size, rate = 1 )
  p_value <- simulate_kruskal(group1,group2,group3,group4)
  for (j in 1:num_levels){
    num_error <- simulation_data$type_I_error[j]
    if (p_value <= alpha_levels[j]){
      num_error <- num_error+1
      simulation_data$type_I_error[j] <- num_error
    }
  }
}
```

**4) Calculate the Proportion**  
Based on each significance level, the probability of a Type I error occurring was calculated:  
\begin{equation}
\text{Type I Error Probability} = \frac{\text{Type I Error Count}}{\text{Total Simulations}}
\end{equation}
***Code Segment***  
```{r}
# Calculate the probability of the type I error for each alpha level
for (j in 1:num_levels){
  rate <- simulation_data$type_I_error[j]/num_trials
  simulation_data$error_probability[j] <- rate
}
print(simulation_data)
```

**5) Analysis of Results**  
Considering the result of this simulation study, it can be observed that the probability of Type I error is close to the corresponding significance level (\(\alpha\)). Moreover, as the significance level increases, the probability of the occurrence of the first type of error gradually increases.  
In conclusion, at the significance level (\(\alpha\)), the simulated Type I error probability is basically consistent with the theoretical value. Additionally, the probability of Type I errors increases with the level of significance, which is consistent with the basic theory of statistics.  
Therefore, this simulation proves that the Kruskal-Wallis test has good reliability.

