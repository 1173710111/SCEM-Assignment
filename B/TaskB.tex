% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={TaskB1},
  pdfauthor={zerofrom},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{TaskB1}
\author{zerofrom}
\date{2024-11-25}

\begin{document}
\maketitle

\subsection{B.1}\label{b.1}

\subsubsection{(1) Value of a}\label{value-of-a}

Considering chat \(x\) follows the probability density function:

\[
p_{\lambda}(x)= \begin{cases}a e^{-\lambda(x-b)} & \text { if } x \geqslant b,  \tag{1}\\ 0 & \text { if } x<b,\end{cases}
\]

The probability density function \(p_{\lambda}(x)\) must follows:

\[
\begin{equation}
\int_{-\infty}^{\infty} p_{\lambda}(x) d x=1 \tag{2}
\end{equation}
\]

Since \(p_{\lambda}(x)=0\) when \(x<b\), it follows that:

\[
\begin{equation}
\int_{b}^{\infty} p_{\lambda}(x) d x=1 \tag{3}
\end{equation}
\]

Replacing expression (1) into expression (3) yields:

\[
\begin{equation}
\int_{b}^{\infty} a e^{-\lambda(x-b)} d x=1 \tag{4}
\end{equation}
\]

Assuming that \(u=x-b\), it can be obtained that:

\[
\begin{equation}
x=u+b, d x=d u \tag{5}
\end{equation}
\]

Assuming that \(x=b\), then \(u=0\), therefore the upper and lower
limits of integration become \(0 \rightarrow \infty\), substituting
expression \((s)\) :

\[
\begin{equation}
\int_{0}^{\infty} a e^{-\lambda u} d u=1 \tag{6}
\end{equation}
\]

Using the exponential integration formula:

\[
\begin{equation}
\int_{0}^{\infty} e^{-a u} d u=\frac{1}{a} \tag{7}
\end{equation}
\]

Thus:

The solution is:

\[
\begin{equation}
a=\frac{1}{\lambda} \tag{9}
\end{equation}
\]

\subsubsection{\texorpdfstring{In conclusion, the value of a is
\(\frac{1}{\lambda}\).}{In conclusion, the value of a is \textbackslash frac\{1\}\{\textbackslash lambda\}.}}\label{in-conclusion-the-value-of-a-is-frac1lambda.}

\paragraph{\texorpdfstring{(2) i) Population Mean \(E[X]\)
:}{(2) i) Population Mean E{[}X{]} :}}\label{i-population-mean-ex}

From the definition of the mean, there is:

\[
\begin{equation}
E[x]=\int_{-\infty}^{\infty} x \cdot p_{\lambda}(x) d x \tag{1}
\end{equation}
\]

Replacing \(p_{\lambda}(x)\) and \(a=\lambda\) :

\[
\begin{equation}
E[x]=\int_{b}^{\infty} x \cdot \lambda e^{-\lambda(x-b)} d x \tag{2}
\end{equation}
\]

Assuming \(u=x-b\), then \(x=u+b\), and \(d x=d u\) :

\[
\begin{align*}
E[X] &= \int_{0}^{\infty}(u + b) \cdot \lambda e^{-\lambda u} \, du \\
     &= \lambda \cdot \int_{0}^{\infty} u e^{-\lambda u} \, du + \lambda b \int_{0}^{\infty} e^{-\lambda u} \, du \tag{3}
\end{align*}
\]

Integral formula for exponential functions:

\[
\begin{equation}
\int_{0}^{\infty} e^{-a x} d x=\frac{1}{a}, \int_{0}^{\infty} x e^{-a x} d x=\frac{1}{a^{2}} \tag{4}
\end{equation}
\]

Replacing expression (t) into expression (3), there is:

\[
\begin{aligned}
E[x] & =\lambda \cdot \frac{1}{\lambda^{2}}+\lambda b \cdot \frac{1}{\lambda} \\
& =\frac{1}{\lambda}+b
\end{aligned}
\]

\subsubsection{\texorpdfstring{In conclusion, the population mean
\(E[x]=\frac{1}{\lambda}+b\).}{In conclusion, the population mean E{[}x{]}=\textbackslash frac\{1\}\{\textbackslash lambda\}+b.}}\label{in-conclusion-the-population-mean-exfrac1lambdab.}

\paragraph{\texorpdfstring{ii) Standard Deviation \(\sigma x\)
:}{ii) Standard Deviation \textbackslash sigma x :}}\label{ii-standard-deviation-sigma-x}

The standard deviation formula:

\[
\begin{equation}
\sigma x=\sqrt{\operatorname{Var}(x)}=\sqrt{E\left[x^{2}\right]-(E[x])^{2}} \tag{1}
\end{equation}
\]

From the derivation of \(E[x]\), it follows that:

\[
E[x]=\frac{1}{\lambda}+b \tag{2}
\]

The formula for \(E\left[x^{2}\right]\) is:

\[
\begin{equation}
E\left[x^{2}\right]=\int_{b}^{\infty} x^{2} \cdot p_{\lambda}(x) d x \tag{3}
\end{equation}
\]

Substituting \(P_{\lambda}(x)\) :

\[
\begin{equation}
E\left[x^{2}\right]=\int_{b}^{\infty} x^{2} \cdot \lambda e^{-\lambda(x-b)} d x \tag{4}
\end{equation}
\]

Assuming \(u=x-b\). then \(x=u+b\), and \(d x=d u\) :

\[
\begin{align*}
E\left[x^{2}\right]= & \int_{0}^{\infty}(u+b)^{2} \cdot \lambda e^{-\lambda u} d u \\
= & \lambda \int_{0}^{\infty}\left(u^{2}+2 b u+b^{2}\right) \cdot e^{-\lambda u} d u \\
= & \lambda \int_{0}^{\infty} u^{2} e^{-\lambda u} d u+2 \lambda b \int_{0}^{\infty} u e^{-\lambda u} d u  +\lambda b^{2} \int_{0}^{\infty} e^{-\lambda u} d u \quad  \tag{5}
\end{align*}
\]

Integrals formula for exponential functions:

\[
\begin{align*}
& \int_{0}^{\infty} e^{-a x} d x=\frac{1}{a} \\
& \int_{0}^{\infty} x e^{-a x} d x=\frac{1}{a^{2}} \\
& \int_{0}^{\infty} x^{2} e^{-a x} d x=\frac{2}{a^{3}} \tag{6}
\end{align*}
\]

Replacing formulas (6) into expression (5), there is:

\[
\begin{align*}
E\left[x^{2}\right] & =\lambda \cdot \frac{2}{\lambda^{3}}+2 \lambda b \cdot \frac{1}{\lambda^{2}}+\lambda b^{2} \cdot \frac{1}{\lambda} \\
& =\frac{2}{\lambda^{2}}+\frac{2 b}{\lambda}+b^{2} \tag{7}
\end{align*}
\]

Replacing expression (2) and (7) into expression (1):

\[
\begin{align*}
\sigma_{x} & =\sqrt{\left(\frac{2}{\lambda^{2}}+\frac{2 b}{\lambda}+b^{2}\right)-\left(\frac{1}{\lambda}+b\right)^{2}} \\
& =\sqrt{\left(\frac{2}{\lambda^{2}}+\frac{2 b}{\lambda}+b^{2}\right)-\left(\frac{1}{\lambda^{2}}+\frac{2 b}{\lambda}+b^{2}\right)} \\
& =\frac{1}{\lambda}
\end{align*}
\]

\subsubsection{\texorpdfstring{In conclusion, the standard deviation of
\(X\) is
\(\sigma_{x}=\frac{1}{\lambda}\).}{In conclusion, the standard deviation of X is \textbackslash sigma\_\{x\}=\textbackslash frac\{1\}\{\textbackslash lambda\}.}}\label{in-conclusion-the-standard-deviation-of-x-is-sigma_xfrac1lambda.}

\paragraph{(3) i) Cumulative distribution function (CDF): Considering
the definition of CDF, it follows
that:}\label{i-cumulative-distribution-function-cdf-considering-the-definition-of-cdf-it-follows-that}

\[
\begin{equation}
F_{x}(x)=P(x \leqslant x)=\int_{-\infty}^{\infty} p_{x}(t) d t . \tag{1}
\end{equation}
\]

If \(x<b\), then \(p_{x}(t)=0\), thus there is:

\[
\begin{equation}
F_{X}(x)=\int_{-\infty}^{x} 0 d t=0 \tag{2}
\end{equation}
\]

If \(x \geqslant b\), then \(p_{x}(t)=\lambda e^{-\lambda(t-b)}\), thus
there is:

\[
\begin{equation}
F_{X}(x)=\int_{b}^{x} \lambda e^{-\lambda(t-b)} d t \tag{3}
\end{equation}
\]

Assuming that \(a=t-b\), then \(t=u+b\). and \(d t=d u\), the upper and
Cower limit of integration becomes \(0 \rightarrow x-b\).

\[
\begin{aligned}
F_{X}(x) & =\int_{0}^{x-b} \lambda e^{-\lambda u} d u \\
& =\lambda \cdot \int_{0}^{x-b} e^{-\lambda u} d u \\
& =\lambda\left[-\frac{1}{\lambda} e^{-\lambda u}\right]_{0}^{x-b} \\
& =\lambda \cdot\left(-\frac{1}{\lambda} e^{-\lambda(x-b)}+\frac{1}{\lambda} e^{0}\right) \\
& =\lambda \cdot\left(-\frac{1}{\lambda} e^{-\lambda(x-b)}+\frac{1}{\lambda}\right) \\
& =-e^{-\lambda(x-b)}+1 
\end{aligned}
\]

\subsubsection{\texorpdfstring{In conclusion, the cumulative
distribution function for the random variable \(x\) is
\(F_{x}(x)= \begin{cases}0, & \text { if } x<b \\ 1-e^{-x(x-b)}, & \text { if } x \geqslant b\end{cases}\)}{In conclusion, the cumulative distribution function for the random variable x is F\_\{x\}(x)= \textbackslash begin\{cases\}0, \& \textbackslash text \{ if \} x\textless b \textbackslash\textbackslash{} 1-e\^{}\{-x(x-b)\}, \& \textbackslash text \{ if \} x \textbackslash geqslant b\textbackslash end\{cases\}}}\label{in-conclusion-the-cumulative-distribution-function-for-the-random-variable-x-is-f_xx-begincases0-text-if-xb-1-e-xx-b-text-if-x-geqslant-bendcases}

\paragraph{ii) Quartile Function (QF)}\label{ii-quartile-function-qf}

Considering the CDF of random variable \(X\) :

\[
F_{X}(x)=\left\{\begin{array}{l}
0, \text { if } x<b  \tag{1}\\
1-e^{-\lambda(x-b),} \text { if } x \geqslant b
\end{array}\right.
\]

Quartile Function \(Q(p)\) satisfies:

\[
\begin{equation}
F_{X}(Q(p))=p \text {, if } 0<p<1 \tag{2}
\end{equation}
\]

Replacing (1) into cl), it follows that:

\[
\begin{equation}
1-e^{-\lambda(x-b)}=p \tag{3}
\end{equation}
\]

Thus there is:

\[
\begin{equation}
e^{-\lambda(x-b)}=1-p \tag{4}
\end{equation}
\]

Taking the natural logarithm of both sides:

\[
\begin{equation}
-\lambda(x-b)=\ln (1-p) \tag{5}
\end{equation}
\]

Thus \[
\begin{equation}
x=b-\frac{\ln (1-p)}{\lambda} \tag{6}
\end{equation}
\] \#\#\# In conclusion, the Quartile Function of random variable \(X\)
is \(Q(p)=b-\frac{\ln (1-p)}{\lambda}, 0<p<1\)

\paragraph{\texorpdfstring{(4) Maxmum Likehood estimat
\MLE:}{(4) Maxmum Likehood estimat :}}\label{maxmum-likehood-estimat}

The definition of likehood function is:

\[
\begin{align*}
L(\lambda) & =\prod_{i=1}^{n} p_{\lambda}\left(x_{i}\right) \\
& =\prod_{i=1}^{n} \lambda e^{-\lambda\left(x_{i}-b\right)} \\
& =\lambda^{n} \prod_{i=1}^{n} e^{-\lambda\left(x_{i}-b\right)} \\
& =\lambda^{n} e^{-\lambda \sum_{i=1}^{n}\left(x_{i}-b\right)} \tag{1}
\end{align*}
\]

Taking the natural logarithm of both sides:

\[
\begin{equation}
\ln L(\lambda)=n \ln \lambda-\lambda \sum_{i=1}^{n}\left(x_{i}-b\right) \tag{2}
\end{equation}
\]

Derivativing with respect to \(\lambda\) :

\[
\begin{equation}
\frac{d \ln L(\lambda)}{d \lambda}=\frac{n}{\lambda}-\sum_{i=1}^{n}\left(x_{i}-b\right) \tag{3}
\end{equation}
\]

Assuming that the derivative is zero, it follows that:

\[
\begin{equation}
\frac{n}{\lambda}-\sum_{i=1}^{n}\left(x_{i}-b\right)=0 \tag{4}
\end{equation}
\]

Calculating the value of \(\lambda\) is:

\[
\begin{equation}
\lambda=\frac{n}{\sum_{i=1}^{n}\left(x_{i-b}\right)} \tag{5}
\end{equation}
\]

\paragraph{\texorpdfstring{In conclusion, the maxmum likehood estimate
for \(x\) is
\(\lambda_{\text {MLE }}=\frac{n}{\sum_{i=1}^{n}\left(x_{i}-b\right)}\)}{In conclusion, the maxmum likehood estimate for x is \textbackslash lambda\_\{\textbackslash text \{MLE \}\}=\textbackslash frac\{n\}\{\textbackslash sum\_\{i=1\}\^{}\{n\}\textbackslash left(x\_\{i\}-b\textbackslash right)\}}}\label{in-conclusion-the-maxmum-likehood-estimate-for-x-is-lambda_text-mle-fracnsum_i1nleftx_i-bright}

\subsubsection{(5) Given the sample, compute and display the maximum
likelihood estimate λMLE of the parameter
λ.}\label{given-the-sample-compute-and-display-the-maximum-likelihood-estimate-ux3bbmle-of-the-parameter-ux3bb.}

\begin{verbatim}
## [1] "The maximum likelihood estimate lambda_MLE is:  0.019884260798572"
\end{verbatim}

\subsubsection{(6) Compute the Bootstrap confidence
interval}\label{compute-the-bootstrap-confidence-interval}

\begin{verbatim}
## [1] "The Bootstrap confidence interval is: [ 0.0191115894121709 , 0.0206792527343937 ]\n"
\end{verbatim}

\subsubsection{(7)) Conduct a simulation study to explore the behaviour
of the maximum likelihood estimator λMLE for λ on simulated data X1, · ·
· ,
Xn}\label{conduct-a-simulation-study-to-explore-the-behaviour-of-the-maximum-likelihood-estimator-ux3bbmle-for-ux3bb-on-simulated-data-x1-xn}

\begin{verbatim}
##   SampleSize        MSE
## 1        100 0.04507438
## 2        110 0.03664986
## 3        120 0.03907616
## 4        130 0.03197187
## 5        140 0.02650689
\end{verbatim}

\includegraphics{TaskB_files/figure-latex/unnamed-chunk-3-1.pdf}

\subsection{B2}\label{b2}

\subsubsection{(1) The formula for the probability mass
function}\label{the-formula-for-the-probability-mass-function}

The range of possible values of the discrete ranom variable \(x\) is:

\[
x \in\{-2,0,2\}
\]

Event 1: Draw 2 blue balls \((X=-2)\)

\[
\begin{aligned}
& C(b, 2)=\frac{b(b-1)}{2}, C(a+b, 2)=\frac{(a+b)(a+b-1)}{2} \\
& \therefore P(x=-2)=\frac{C(b, 2)}{C(a+b, 2)}=\frac{b(b-1)}{(a+b)(a+b-1)}
\end{aligned}
\]

Event 2: Draw 1 red ball and 1 blue ball \((x=0)\)

\[
\begin{aligned}
& C(a, 1) \cdot C(b, 1)+C(b, 1) \cdot C(a, 1)=2 \cdot a \cdot b \\
\therefore  & P(X=0)=\frac{C(a, 1) C(b, 1)+C(b, 1) C(a, 1)}{C(a+b, 2)}\\
&=\frac{2 a b}{(a+b)(a+b-1)}
\end{aligned}
\]

Event 3: Draw 2 red balls \((x=2)\)

\[
\begin{aligned}
C(a, 2) & =\frac{a(a-1)}{2} \\
\therefore P(x=2) & =\frac{C(a, 2)}{C(a+b, 2)}=\frac{a(a-1)}{(a+b)(a+b-1)}
\end{aligned}
\]

\subsubsection{In conclustion, the formula for the probability mass
function
pros:}\label{in-conclustion-the-formula-for-the-probability-mass-function-pros}

\[
P(x)= \begin{cases}\frac{b(b-1)}{(a+b)(a+b-1)} & , x=-2 \\ \frac{2a b}{(a+b)(a+b-1)} & , x=0 \\ \frac{a(a-1)}{(a+b)(a+b-1)} & , x=2\end{cases}
\]

\subsubsection{(2) The expression of the
expectation}\label{the-expression-of-the-expectation}

According to the expectation formula for random variables:

\[
\begin{equation}
E(X)=\sum_{x \in\{-2,0,2\}} x \cdot P(X=x) \tag{1}
\end{equation}
\]

Replacing \(P(x)\) into (1) , there is:

\[
\begin{align*}
E(x) & =-2 \cdot \frac{b(b-1)}{(a+b)(a+b-1)}+2 \cdot \frac{a(a-1)}{(a+b)(a+b-1)} \\
& =\frac{2 a(a-1)-2 b(b-1)}{(a+b)(a+b-1)} \\
& =\frac{2\left(a^{2}-b^{2}-a+b\right)}{(a+b)(a+b-1)} \tag{2}
\end{align*}
\]

\subsubsection{\texorpdfstring{In conclusion, the expectation \(E(X)\)
of \(X\)
is:}{In conclusion, the expectation E(X) of X is:}}\label{in-conclusion-the-expectation-ex-of-x-is}

\[
E(X)=\frac{2\left(a^{2}-b^{2}-a+b\right)}{(a+b)(a+b-1)}
\]

\subsubsection{(3)The expression of the variance
Var(X)}\label{the-expression-of-the-variance-varx}

According to the formula of \(E\left(X^{2}\right)\) :

\[
\begin{equation}
E\left(X^{2}\right)=\sum_{x \in\{-2,0,2\}} x^{2} \cdot P(X=x) \tag{1}
\end{equation}
\]

Replacing \(P(x)\) in to \((1)\), there is:

\[
\begin{align*}
E\left(x^{2}\right) & =4 \cdot \frac{b(b-1)}{(a+b)(a+b-1)}+4 \cdot \frac{a(a-1)}{(a+b)(a+b-1)} \\
& =\frac{4\left(a^{2}+b^{2}-a-b\right)}{(a+b)(a+b-1)} \tag{2}
\end{align*}
\]

According to the formula of \(\operatorname{Var}(X)\) :

\[
\begin{equation}
\operatorname{Var}(x)=E\left(x^{2}\right)-[E(x)]^{2} \tag{3}
\end{equation}
\]

Replacing \(E\left(x^{2}\right)\) and \(E(x)\) into (3), it follows
that:

\[
\begin{aligned}
\operatorname{Var}(x) & =\frac{4\left(a^{2}+b^{2}-a-b\right)}{(a+b)(a+b-1)}-\left[\frac{2\left(a^{2}-b^{2}-a+b\right)}{(a+b)(a+b-1)}\right]^{2} \\
& =\frac{4\left(a^{2}+b^{2}-a-b\right)(a+b)(a+b-1)-4\left(a^{2}-b^{2}-a+b\right)^{2}}{(a+b)^{2}(a+b-1)^{2}}
\end{aligned}
\] \#\#\# In conclusion, the expression of the variance Var(X) is:\\
\[
\begin{aligned}
\operatorname{Var}(x) & =\frac{4\left(a^{2}+b^{2}-a-b\right)(a+b)(a+b-1)-4\left(a^{2}-b^{2}-a+b\right)^{2}}{(a+b)^{2}(a+b-1)^{2}}
\end{aligned}
\] \#\#\# (4)Write a function called compute\_expectation\_X that takes
a and b as inputs and outputs the expectation E(X). Write a function
called compute\_variance\_X that takes a and b as input and outputs the
variance Var(X).

\subsubsection{(5) The expression of the expectation of the random
variable
X}\label{the-expression-of-the-expectation-of-the-random-variable-x}

According to the linear nature of the mean of a random variable:

\[
\begin{equation}
E(\bar{X})=E\left(\frac{1}{n} \sum_{i=1}^{n} X_{i}\right)=\frac{1}{n} \sum_{i=1}^{n} E\left(X_{i}\right) \tag{1}
\end{equation}
\]

\(\because X_{i}\) are i.i.d., thus \(E\left(X_{i}\right)=E(x)\), thus:

\[
\begin{equation}
E(\bar{X})=\frac{1}{n} \cdot n \cdot E(X)=E(X) \tag{2} 
\end{equation}
\]

\subsubsection{\texorpdfstring{In conclusion, the expression of the
expectation of the random variable \(\bar{x}\) is:
\(E(\bar{X})=\frac{2\left(a^{2}-b^{2}-a+b\right)}{(a+b)(a+b-1)}\)}{In conclusion, the expression of the expectation of the random variable \textbackslash bar\{x\} is: E(\textbackslash bar\{X\})=\textbackslash frac\{2\textbackslash left(a\^{}\{2\}-b\^{}\{2\}-a+b\textbackslash right)\}\{(a+b)(a+b-1)\}}}\label{in-conclusion-the-expression-of-the-expectation-of-the-random-variable-barx-is-ebarxfrac2lefta2-b2-abrightabab-1}

\subsubsection{(6) The expression of the variance of the random variable
X}\label{the-expression-of-the-variance-of-the-random-variable-x}

Considering the effect of a linear transformation of a random variable
on the variance :

\[
\begin{equation}
\operatorname{Var}(a X+b)=a^{2} \operatorname{Var}(X)  \tag{1}\\
\end{equation}
\] thus: \[
\begin{align*}
&\operatorname{Var}(\bar{X})=\operatorname{Var}\left(\frac{1}{n} \sum_{i=1}^{n} X_{i}\right) \\
&=\frac{1}{n^{2}} \operatorname{Var}\left(\sum_{i=1}^{n} X_{i}\right) \\
&=\frac{1}{n^{2}} \cdot n \operatorname{Var}(X) \\
&=\frac{1}{n} \operatorname{Var}(X) \tag{2}
\end{align*}
\]

\subsubsection{\texorpdfstring{In conclusion, the expression of the
variance of the random variable \(\bar{X}\)
is}{In conclusion, the expression of the variance of the random variable \textbackslash bar\{X\} is}}\label{in-conclusion-the-expression-of-the-variance-of-the-random-variable-barx-is}

\[
\operatorname{Var}(\bar{X})=\frac{4\left(a^{2}+b^{2}-a-b\right)(a+b)(a+b-1)-4\left(a^{2}-b^{2}-a+b\right)^{2}}{n(a+b)^{2}(a+b-1)^{2}}
\] \#\#\# (7) Create a function called sample\_Xs

\subsubsection{\texorpdfstring{(8) Calculate
E(X),Var(X),E(\bar\{X\}),Var(\bar\{X\})}{(8) Calculate E(X),Var(X),E(\{X\}),Var(\{X\})}}\label{calculate-exvarxexvarx}

\begin{verbatim}
## [1] "Expectation E(X): -0.5 \n"
\end{verbatim}

\begin{verbatim}
## [1] "Expectation of samples E(bar{X}): -0.501 \n"
\end{verbatim}

\begin{verbatim}
## [1] "Variance Var(X): 1.60714285714286 \n"
\end{verbatim}

\begin{verbatim}
## [1] "Variance of samples Var(bar{X}): 1.60309503095031 \n"
\end{verbatim}

\subsubsection{(9) Compute the corresponding sample mean X based on X1,
· · · ,
Xn}\label{compute-the-corresponding-sample-mean-x-based-on-x1-xn}

\subsubsection{(10) Create a scatter plot of the
points}\label{create-a-scatter-plot-of-the-points}

\begin{verbatim}
## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## i Please use `linewidth` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.
\end{verbatim}

\includegraphics{TaskB_files/figure-latex/unnamed-chunk-8-1.pdf}

\subsubsection{(11) Describe the relationship between the density of X
and the function fµ,σ displayed in your plot. Try to explain the
reason.}\label{describe-the-relationship-between-the-density-of-x-and-the-function-fuxb5ux3c3-displayed-in-your-plot.-try-to-explain-the-reason.}

\begin{enumerate}
\def\labelenumi{(\roman{enumi})}
\tightlist
\item
  The blue points in the figure depicts the density distribution of the
  mean of the discrete random variable X over the interval {[}µ - 3σ, µ
  + 3σ{]}, satisfying the normal distribution.
\item
  The red curve in the figure is the kernel density estimate obtained by
  representing the kernel density of the sample mean X within simulation
  study with 50000 trials.
\item
  It can be seen that the two are very close to each other, proving that
  the sampling distribution of the sample means tends to the standard
  normal distribution when the sample size is large enough.
\end{enumerate}

\end{document}
